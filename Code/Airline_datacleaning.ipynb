{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728eb810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to the current directory containing the CSV files\n",
    "folder_path = '.'  # Current directory\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Parameters for filtering\n",
    "delay_threshold = 120  # Delay threshold in minutes\n",
    "\n",
    "# Process each file separately\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "    \n",
    "    # Convert FlightDate to datetime\n",
    "    df['FlightDate'] = pd.to_datetime(df['FlightDate'], errors='coerce')\n",
    "    \n",
    "    # Convert time columns to datetime format\n",
    "    df['CRSDepTime_timezone'] = pd.to_datetime(df['CRSDepTime_timezone'], errors='coerce')\n",
    "    df['DepTime_timezone'] = pd.to_datetime(df['DepTime_timezone'], errors='coerce')\n",
    "    df['CRSArrTime_timezone'] = pd.to_datetime(df['CRSArrTime_timezone'], errors='coerce')\n",
    "    df['ArrTime_timezone'] = pd.to_datetime(df['ArrTime_timezone'], errors='coerce')\n",
    "    \n",
    "    # Extract year from FlightDate\n",
    "    year = df['FlightDate'].dt.year.iloc[0]  # Assumes each file contains data from only one year\n",
    "    \n",
    "    # Filter for the 2022 Seattle-specific Alaska Airlines issue\n",
    "    if year == 2022:\n",
    "        alaska_seattle_data = df[\n",
    "            ((df['Marketing_Airline_Network'] == 'AS') | (df['DOT_ID_Operating_Airline'] == 'AS')) &  # Alaska Airlines\n",
    "            ((df['Origin'] == 'SEA') | (df['Dest'] == 'SEA')) &  # Seattle-Tacoma International Airport (SEA)\n",
    "            ((df['DepDelay'] > delay_threshold) | (df['ArrDelay'] > delay_threshold))  # Significant delays\n",
    "        ]\n",
    "        # Remove these identified rows from the data\n",
    "        df = df.drop(alaska_seattle_data.index)\n",
    "    \n",
    "    # Filter out rows with significant delays likely due to snowstorms\n",
    "    outliers = df[\n",
    "        (df['DepDelay'] > delay_threshold) |\n",
    "        (df['ArrDelay'] > delay_threshold) |\n",
    "        (df.get('CarrierDelay', 0) > delay_threshold) |\n",
    "        (df.get('WeatherDelay', 0) > delay_threshold) |\n",
    "        (df.get('NASDelay', 0) > delay_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Remove the identified snowstorm-related delay outliers\n",
    "    df = df.drop(outliers.index)\n",
    "    \n",
    "    # Define a new filename for the cleaned data\n",
    "    base_name = os.path.basename(file)\n",
    "    cleaned_filename = f\"cleaned_{base_name}\"\n",
    "    cleaned_filepath = os.path.join(folder_path, cleaned_filename)\n",
    "    \n",
    "    # Save the cleaned dataset for this file\n",
    "    df.to_csv(cleaned_filepath, index=False)\n",
    "    print(f\"Cleaned data saved as {cleaned_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = '.'\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Process each file separately\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "    \n",
    "    # Check if both required columns are present before creating flight_id\n",
    "    if 'Marketing_Airline_Network' in df.columns and 'Flight_Number_Marketing_Airline' in df.columns:\n",
    "        # Combine 'Marketing_Airline_Network' and 'Flight_Number_Marketing_Airline' into 'flight_id'\n",
    "        df['flight_id'] = df['IATA_Code_Operating_Airline'].astype(str) + df['Flight_Number_Operating_Airline'].astype(str)\n",
    "        \n",
    "        # Drop the original columns\n",
    "        df = df.drop(['Flight_Number_Operating_Airline'], axis=1)\n",
    "        \n",
    "        # Insert 'flight_id' as the fourth column (index 3)\n",
    "        flight_id_col = df.pop('Operating_flight_id')  # Remove 'flight_id' temporarily\n",
    "        df.insert(5, 'Operating_flight_id', flight_id_col)  # Insert 'flight_id' at index 3\n",
    "        \n",
    "        # Define a new filename for the modified data\n",
    "        base_name = os.path.basename(file)\n",
    "        modified_filename = f\"modified_{base_name}\"\n",
    "        modified_filepath = os.path.join(folder_path, modified_filename)\n",
    "        \n",
    "        # Save the modified dataset for this file\n",
    "        df.to_csv(modified_filepath, index=False)\n",
    "        print(f\"Modified data with flight_id saved as {modified_filename}\")\n",
    "    else:\n",
    "        print(f\"Skipping {file}: Required columns not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750eaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the current directory containing the CSV files\n",
    "folder_path = '.'  \n",
    "csv_files = sorted(glob.glob(os.path.join(folder_path, '*.csv')))  # Sort files to ensure correct order\n",
    "\n",
    "# Initialize the starting index for the first file\n",
    "start_index = 1\n",
    "\n",
    "# Process each file with a sequential index range\n",
    "for file in csv_files:\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "    \n",
    "    # Set the index to start from the current starting index\n",
    "    df.index = range(start_index, start_index + len(df))\n",
    "    \n",
    "    # Drop the second column if it exists\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    # Define a new filename for the modified data\n",
    "    base_name = os.path.basename(file)\n",
    "    indexed_filename = f\"{base_name}\"\n",
    "    indexed_filepath = os.path.join(folder_path, indexed_filename)\n",
    "    \n",
    "    # Save the modified dataset for this file with the updated index\n",
    "    df.to_csv(indexed_filepath, index=True)  # Save with index\n",
    "    print(f\"Data with updated index saved as {indexed_filename}\")\n",
    "    \n",
    "    # Update the starting index for the next file based on the number of rows in the current file\n",
    "    start_index += len(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
